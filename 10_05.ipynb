{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N 개의 Decision Tree가 voting을 통해 결정하는 방식\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 1.0\n",
      "Test accuracy : 0.7692307692307693\n",
      "confusion_matrix : \n",
      " [[53 11]\n",
      " [13 27]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pydot\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/liver.csv')\n",
    "\n",
    "df_X = df.loc [:, df.columns != 'category']\n",
    "df_y= df['category']\n",
    "\n",
    "train_X , test_X , train_y , test_y = train_test_split(df_X , df_y , test_size = 0.3, random_state = 1234)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=50 , random_state=1234)\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('Train accuracy :', model.score(train_X , train_y))\n",
    "print('Test accuracy :', model.score(test_X , test_y))\n",
    "print('confusion_matrix : \\n', confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine(SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original SVM\n",
    "- Class 내에서 Support Vector점을 찾아 분류하는 방식\n",
    "\n",
    "Kernel Method\n",
    "- 2차원 클래스를 고차원으로 치환하여 분류\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.7178423236514523\n",
      "Test accuracy : 0.7788461538461539\n"
     ]
    }
   ],
   "source": [
    "# Basic Model\n",
    "model = svm.SVC()\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "print('Train accuracy :', model.score(train_X , train_y))\n",
    "print('Test accuracy :', model.score(test_X , test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.7385892116182573\n",
      "Test accuracy : 0.7596153846153846\n"
     ]
    }
   ],
   "source": [
    "# Kernel Model\n",
    "model = svm.SVC(kernel='poly')\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "print('Train accuracy :', model.score(train_X , train_y))\n",
    "print('Test accuracy :', model.score(test_X , test_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 틀린 데이터에 대한 가중치를 통해 새로운 모델을 생성. 이러한 과정을 반복.   \n",
    "Boosting방식이 Bagging방식보다 조금더 성능이 좋다.\n",
    "- params 참고 https://dining-developer.tistory.com/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7692307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "D_train = xgb.DMatrix(train_X, label = train_y)\n",
    "D_test = xgb.DMatrix(test_X, label = test_y)\n",
    "\n",
    "param = {\n",
    "    'eta': 0.2,\n",
    "    'max_depth': 3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'error'\n",
    "    }\n",
    "steps = 20\n",
    "\n",
    "model = xgb.train(param, D_train, steps)\n",
    "\n",
    "pred = model.predict(D_test)\n",
    "round_preds = np.round(pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(test_y , round_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
