{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'B' 'C' 'D' 'E' 'F']\n",
      "[0 2 0 ... 3 2 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train = pd.read_csv('dataset/train_open.csv')\n",
    "\n",
    "# map_label = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6}\n",
    "# col = ['32']\n",
    "# train[col] = train[col].applymap(map_label.get)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "data_X = train.loc[:, train.columns != '32']\n",
    "data_y = encoder.fit_transform(train['32'])\n",
    "data_y = np.array(data_y)\n",
    "\n",
    "print(encoder.classes_)\n",
    "print(data_y)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(data_X, data_y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparison\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20']\n",
      "0.5714\n",
      "['20', '8']\n",
      "0.5968\n",
      "['20', '8', '11']\n",
      "0.6059\n",
      "['20', '8', '11', '19']\n",
      "0.6384\n",
      "['20', '8', '11', '19', '13']\n",
      "0.6598\n",
      "['20', '8', '11', '19', '13', '29']\n",
      "0.8097\n",
      "['20', '8', '11', '19', '13', '29', '2']\n",
      "0.8287\n",
      "['20', '8', '11', '19', '13', '29', '2', '7']\n",
      "0.8803\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14']\n",
      "0.8822\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16']\n",
      "0.8882\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24']\n",
      "0.8914\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17']\n",
      "0.8949\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4']\n",
      "0.8906\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5']\n",
      "0.9005\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22']\n",
      "0.8937\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22', '26']\n",
      "0.8977\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22', '26', '10']\n",
      "0.9013\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22', '26', '10', '1']\n",
      "0.8957\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22', '26', '10', '1', '27']\n",
      "0.8977\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22', '26', '10', '1', '27', '25']\n",
      "0.8965\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22', '26', '10', '1', '27', '25', '30']\n",
      "0.8993\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22', '26', '10', '1', '27', '25', '30', '15']\n",
      "0.8949\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22', '26', '10', '1', '27', '25', '30', '15', '6']\n",
      "0.8949\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22', '26', '10', '1', '27', '25', '30', '15', '6', '23']\n",
      "0.8937\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22', '26', '10', '1', '27', '25', '30', '15', '6', '23', '9']\n",
      "0.8945\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22', '26', '10', '1', '27', '25', '30', '15', '6', '23', '9', '21']\n",
      "0.8965\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22', '26', '10', '1', '27', '25', '30', '15', '6', '23', '9', '21', '3']\n",
      "0.8929\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22', '26', '10', '1', '27', '25', '30', '15', '6', '23', '9', '21', '3', '18']\n",
      "0.8933\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22', '26', '10', '1', '27', '25', '30', '15', '6', '23', '9', '21', '3', '18', '12']\n",
      "0.8921\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22', '26', '10', '1', '27', '25', '30', '15', '6', '23', '9', '21', '3', '18', '12', '31']\n",
      "0.8894\n",
      "['20', '8', '11', '19', '13', '29', '2', '7', '14', '16', '24', '17', '4', '5', '22', '26', '10', '1', '27', '25', '30', '15', '6', '23', '9', '21', '3', '18', '12', '31', '28']\n",
      "0.8929\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "test = SelectKBest(score_func=chi2, k=train_X.shape[1])\n",
    "fit = test.fit(train_X, train_y)\n",
    "\n",
    "f_order = np.argsort(-fit.scores_) # sort index by decreasing order\n",
    "sorted_columns = train.columns[f_order]\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "for i in range(1, train_X.shape[1]+1):\n",
    "    fs = sorted_columns[0:i]\n",
    "    df_X_selected = train_X[fs]\n",
    "    scores = cross_val_score(model, df_X_selected, train_y, cv=5)\n",
    "    print(fs.tolist())\n",
    "    print(np.round(scores.mean(), 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', '2', '4', '5', '6', '7', '8', '14', '15', '16', '19', '20', '24', '26', '29', '30', '31')\n",
      "Acc: 0.8925483262611976\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "sfs1 = SFS(model, k_features=17, verbose=0, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "sfs1 = sfs1.fit(train_X, train_y)\n",
    "\n",
    "print(sfs1.k_feature_names_) # selected feature name\n",
    "\n",
    "scores = cross_val_score(model, train_X[list(sfs1.k_feature_names_)], train_y, cv=5)\n",
    "print(\"Acc: \"+str(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "{'bootstrap': False,\n",
      " 'max_depth': None,\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 2,\n",
      " 'n_estimators': 1600}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1234)\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=10)]\n",
    "max_depth.append(None)\n",
    "\n",
    "rand_list = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [int(x) for x in np.linspace(2, 20, num=1)],\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "}\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(estimator=rf, param_distributions=rand_list, cv=5, n_jobs=-1, verbose=2, scoring=\"accuracy\")\n",
    "random_search_rf.fit(train_X[list(sfs1.k_feature_names_)], train_y)\n",
    "pp.pprint(random_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6857670979667283"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "D_train = xgb.DMatrix(train_X, label=train_y)\n",
    "D_test = xgb.DMatrix(test_X, label=test_y)\n",
    "\n",
    "random_list = {\n",
    "    'booster': 'gbtree',\n",
    "    'eta': 0.2,\n",
    "    'max_depth' : 3,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'error',\n",
    "}\n",
    "steps = 20\n",
    "\n",
    "xg = xgb.train(random_list, D_train, steps)\n",
    "\n",
    "random_search_xg = RandomizedSearchCV(estimator=xg, param_distributions=rand_list, cv=5, n_jobs=-1, verbose=2, scoring=\"accuracy\")\n",
    "random_search_xg.fit(train_X[list(sfs1.k_feature_names_)], train_y)\n",
    "pp.pprint(random_search_xg.best_params_)\n",
    "pp.pprint(random_search_xg.best_score_)\n",
    "\n",
    "pred = model.predict(D_test)\n",
    "\n",
    "round_preds = np.round(pred) # real -> [0,1]\n",
    "accuracy_score(test_y, round_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "{'C': 2.209602254061174, 'gamma': 0.8670701646824878}\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "svc = SVC(probability = True, random_state = 1)\n",
    "\n",
    "rand_list = {\"C\": stats.uniform(2, 10),\n",
    "             \"gamma\": stats.uniform(0.1, 1)}\n",
    "              \n",
    "random_search_svc = RandomizedSearchCV(estimator=svc, param_distributions = rand_list, n_iter = 20, n_jobs = -1, cv = 5, random_state = 2017, scoring = \"accuracy\", verbose=2) \n",
    "random_search_svc.fit(train_X[list(sfs1.k_feature_names_)], train_y) \n",
    "pp.pprint(random_search_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "{'leaf_size': 12, 'n_neighbors': 7, 'p': 1}\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "rand_list = {\n",
    "    \"leaf_size\" : [int(x) for x in range(1,50)],\n",
    "    \"n_neighbors\" : [int(x) for x in range(1,30)],\n",
    "    \"p\" : [1,2],\n",
    "}\n",
    "\n",
    "random_search_knn = RandomizedSearchCV(estimator=knn, param_distributions=rand_list, n_jobs = -1, cv = 5, verbose=2)\n",
    "random_search_knn.fit(train_X[list(sfs1.k_feature_names_)], train_y) \n",
    "pp.pprint(random_search_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "{'criterion': 'entropy',\n",
      " 'max_depth': None,\n",
      " 'min_samples_leaf': 3,\n",
      " 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=10)]\n",
    "max_depth.append(None)\n",
    "\n",
    "rand_list = {\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_leaf': [int(x) for x in range(1, 5)],\n",
    "    'min_samples_split': [int(x) for x in range(2, 11)],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "random_search_dt = RandomizedSearchCV(estimator=dt, param_distributions=rand_list, n_jobs = -1, cv = 5, verbose=2, random_state=1234)\n",
    "random_search_dt.fit(train_X[list(sfs1.k_feature_names_)], train_y) \n",
    "pp.pprint(random_search_dt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NBH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\NBH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\NBH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\NBH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\NBH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\NBH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\NBH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\NBH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\NBH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\NBH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\NBH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.81007544 0.81324061        nan        nan 0.8235565  0.844967\n",
      " 0.81998821 0.82196527 0.79817382        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\NBH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.0031968399196034697, 'penalty': 'none', 'solver': 'newton-cg'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NBH\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import loguniform\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "rand_list = {\n",
    "    \"solver\" : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    \"penalty\" : ['none', 'l1', 'l2', 'elasticnet'],\n",
    "    \"C\" : loguniform(1e-5, 100)\n",
    "}\n",
    "\n",
    "random_search_lr = RandomizedSearchCV(estimator=lr, param_distributions=rand_list, n_jobs = -1, cv = 5, verbose=2, random_state=1234)\n",
    "random_search_lr.fit(train_X[list(sfs1.k_feature_names_)], train_y) \n",
    "pp.pprint(random_search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LR: 0.845733 (0.022157)\n",
      " KNN: 0.865988 (0.020667)\n",
      "  DT: 0.835182 (0.020455)\n",
      "  RF: 0.899555 (0.021576)\n",
      " SVM: 0.231393 (0.024351)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAHNCAYAAADMjHveAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0sUlEQVR4nO3de1yUZf7/8fcwyPmghoLaJKYWWCaKyarlZmGYZtl2MA9hpNSv1A60bVEpHUVtUyrdrFazsr65ldvB1A6k7bpa7kJuWaCdSFJBqQQDxWTu3x/FtBOgzMhwCbyej8f9cLm5rvv63DPbzJt7rvsam2VZlgAAAAzxM10AAABo2wgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMII0ArZrPZdM8993jcr6ioSDabTcuWLWvymo7mnnvukc1ma/ZxJe8fLwDHhjAC+NiyZctks9lks9m0YcOGOr+3LEsOh0M2m00XXnihgQqPTVFRkdLS0tSzZ08FBQUpJiZGw4YNU1ZWlunS6rV69WoCB3Cc8TddANBWBAUF6YUXXtBZZ53ltv/999/Xt99+q8DAQEOVee+LL77QmWeeqeDgYF1zzTWKjY3V7t27lZ+fr7lz5+ree+81XWIdq1ev1qJFi+oNJAcOHJC/Py+LQHPjvzqgmYwaNUovvfSSHn30Ubc3vBdeeEGJiYkqKyszWJ13FixYoB9//FFbtmxR9+7d3X63Z88eQ1V5LygoyHQJQJvExzRAMxk/fry+++47vfPOO659hw4d0ssvv6wJEybU26eyslK33nqrHA6HAgMDdeqpp+rPf/6zfvtl29XV1brlllvUqVMnhYeH66KLLtK3335b7zF37typa665RtHR0QoMDNRpp52mpUuXenVOX375pU488cQ6QUSSOnfuXGffmjVrdPbZZys0NFTh4eEaPXq0Pv3000aNtXz5ciUmJio4OFgdO3bUlVdeqeLi4jrtPvzwQ40aNUodOnRQaGiozjjjDD3yyCOSpKuvvlqLFi2SJNdHZ/87P6W+OSMfffSRLrjgAkVERCgsLEznnXeePvjgA7c2tR/F/etf/1JGRoY6deqk0NBQXXLJJdq7d2+jzg9oywgjQDOJjY3V4MGD9X//93+ufWvWrFF5ebmuvPLKOu0ty9JFF12kBQsWaOTIkZo/f75OPfVU3XbbbcrIyHBrO3XqVOXk5Oj888/XnDlz1K5dO40ePbrOMUtLS/W73/1O7777rqZPn65HHnlEvXr10pQpU5STk+PxOXXv3l3FxcV67733jtr2ueee0+jRoxUWFqa5c+dq5syZ+uyzz3TWWWepqKjoiH0ffPBBpaamqnfv3po/f75uvvlm5ebmatiwYdq3b5+r3TvvvKNhw4bps88+00033aSHH35Yw4cP16pVqyRJ1113nUaMGOGqp3ZryKeffqqzzz5b//3vf/WnP/1JM2fO1Ndff61zzjlHH374YZ32M2bM0H//+19lZWXp+uuv1xtvvKHp06cf9bEB2jwLgE89/fTTliTr3//+t7Vw4UIrPDzcqqqqsizLsi6//HJr+PDhlmVZVvfu3a3Ro0e7+r366quWJOuBBx5wO95ll11m2Ww264svvrAsy7K2bNliSbJuuOEGt3YTJkywJFlZWVmufVOmTLG6dOlilZWVubW98sorrcjISFddX3/9tSXJevrpp494blu3brWCg4MtSVZCQoJ10003Wa+++qpVWVnp1m7//v1W+/btrfT0dLf9JSUlVmRkpNv+rKws639fmoqKiiy73W49+OCDbn0/+eQTy9/f37X/8OHDVo8ePazu3btbP/zwg1tbp9Pp+t/Tpk2zGnrp++3jNXbsWCsgIMD68ssvXft27dplhYeHW8OGDXPtq32Ok5OT3ca65ZZbLLvdbu3bt6/e8QD8jCsjQDO64oordODAAa1atUr79+/XqlWrGvyIZvXq1bLb7brxxhvd9t96662yLEtr1qxxtZNUp93NN9/s9rNlWXrllVc0ZswYWZalsrIy15aSkqLy8nLl5+d7dD6nnXaatmzZokmTJqmoqEiPPPKIxo4dq+joaD311FOudu+884727dun8ePHu41rt9uVlJSkdevWNTjGypUr5XQ6dcUVV7j1jYmJUe/evV19P/roI3399de6+eab1b59e7djeHOrcE1Njd5++22NHTtWJ598smt/ly5dNGHCBG3YsEEVFRVufa699lq3sc4++2zV1NTom2++8Xh8oC1hAivQjDp16qTk5GS98MILqqqqUk1NjS677LJ6237zzTfq2rWrwsPD3fbHx8e7fl/7r5+fn3r27OnW7tRTT3X7ee/evdq3b5+efPJJPfnkk/WO6c2k01NOOUXPPfecampq9Nlnn2nVqlWaN2+err32WvXo0UPJycn6/PPPJUnnnntuvceIiIho8Piff/65LMtS79696/19u3btJP08f0WSTj/9dI/PoT579+5VVVVVncdR+vk5cDqdKi4u1mmnnebaf9JJJ7m169ChgyTphx9+aJKagNaKMAI0swkTJig9PV0lJSW64IIL6vwV7ytOp1OSNGnSJE2ePLneNmeccYbXx7fb7erbt6/69u2rwYMHa/jw4Xr++eeVnJzsGvu5555TTExMnb5Hup3W6XTKZrNpzZo1stvtdX4fFhbmdc1Nrb76JNWZcAzAHWEEaGaXXHKJrrvuOn3wwQdasWJFg+26d++ud999V/v373e7OlJYWOj6fe2/TqdTX375pdtf8du2bXM7Xu2dNjU1NUpOTm7KU6pj4MCBkqTdu3dLkuuqTefOnT0eu2fPnrIsSz169NApp5xyxHaStHXr1iOO0diPbDp16qSQkJA6j6P083Pg5+cnh8PRqGMBODLmjADNLCwsTI8//rjuuecejRkzpsF2o0aNUk1NjRYuXOi2f8GCBbLZbLrgggskyfXvo48+6tbut3fH2O12XXrppXrllVe0devWOuN5cwvqP//5T/3000919tfOY6kNRykpKYqIiNDs2bPrbX+ksf/whz/Ibrfr3nvvrXOFwbIsfffdd5KkAQMGqEePHsrJyXG7w6a2Xa3Q0FBJqtPmt+x2u84//3y99tprbnf7lJaWuhavO9LHSwAajysjgAENfUzyv8aMGaPhw4frrrvuUlFRkfr166e3335br732mm6++WbXlYCEhASNHz9ef/nLX1ReXq4hQ4YoNzdXX3zxRZ1jzpkzR+vWrVNSUpLS09PVp08fff/998rPz9e7776r77//3qPzmDt3rvLy8vSHP/zB9RFPfn6+nn32WXXs2NE1iTYiIkKPP/64rrrqKg0YMEBXXnmlOnXqpB07dujNN9/U0KFD64SuWj179tQDDzygzMxMFRUVaezYsQoPD9fXX3+tv//977r22mv1xz/+UX5+fnr88cc1ZswYJSQkKC0tTV26dFFhYaE+/fRTvfXWW5KkxMREST9P+E1JSZHdbq/31mpJeuCBB/TOO+/orLPO0g033CB/f3898cQTqq6u1rx58zx6rAAcgbH7eIA24n9v7T2S397aa1k/3xJ7yy23WF27drXatWtn9e7d23rooYfcbh+1LMs6cOCAdeONN1onnHCCFRoaao0ZM8YqLi6uc6uqZVlWaWmpNW3aNMvhcFjt2rWzYmJirPPOO8968sknXW0ae2vvv/71L2vatGnW6aefbkVGRlrt2rWzTjrpJOvqq692ux221rp166yUlBQrMjLSCgoKsnr27GldffXV1n/+8x9Xm9/e2lvrlVdesc466ywrNDTUCg0NteLi4qxp06ZZ27Ztc2u3YcMGa8SIEVZ4eLgVGhpqnXHGGdZjjz3m+v3hw4etGTNmWJ06dbJsNpvbWPU9Xvn5+VZKSooVFhZmhYSEWMOHD7c2btzo1qah53jdunWWJGvdunVHfByBts5mWcysAgAA5jBnBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGCUv+kCGsPpdGrXrl0KDw+XzWYzXQ4AAGgEy7K0f/9+de3aVX5+DV//aBFhZNeuXXI4HKbLAAAAXiguLtaJJ57Y4O9bRBgJDw+X9PPJREREGK4GAAA0RkVFhRwOh+t9vCEtIozUfjQTERFBGAEAoIU52hQLJrACAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMahFflAcA8FxVVZUKCwsb3f7AgQMqKipSbGysgoODG90vLi5OISEh3pQISCKMAECrVVhYqMTERJ+Pk5eXpwEDBvh8HLRehBEAaKXi4uKUl5fX6PYFBQWaNGmSli9frvj4eI/GAY4FYQQAWqmQkBCvrljEx8dzpQPNigmsAADAKMIIAAAwijACAACMIowAAACjCCMAAMAo7qYBgBbi888/1/79+312/IKCArd/fSU8PFy9e/f26RhoWQgjANACfP755zrllFOaZaxJkyb5fIzt27cTSODiVRhZtGiRHnroIZWUlKhfv3567LHHNGjQoHrb/vTTT8rOztYzzzyjnTt36tRTT9XcuXM1cuTIYyocANqS2isini5I5glvl4P3RO3Car68woOWx+MwsmLFCmVkZGjx4sVKSkpSTk6OUlJStG3bNnXu3LlO+7vvvlvLly/XU089pbi4OL311lu65JJLtHHjRvXv379JTgIAWjvb4YPqH+OnAV3sio/x1XS/UA3tcZqPjv2z4H129Y/xk+3wQZ+Og5bFZlmW5UmHpKQknXnmmVq4cKEkyel0yuFwaMaMGbrjjjvqtO/atavuuusuTZs2zbXv0ksvVXBwsJYvX96oMSsqKhQZGany8nJFRER4Ui4AtAoF772o+H9cZ7qMJlMw7AnFn3ul6TLgY419//boysihQ4eUl5enzMxM1z4/Pz8lJydr06ZN9faprq5WUFCQ277g4GBt2LChwXGqq6tVXV3t+rmiosKTMgGg1TkYdpIGPPGjnn/+ecW34O+CKSgs1MSJE7Vk1EmmS8FxxKMwUlZWppqaGkVHR7vtj46ObvBrqlNSUjR//nwNGzZMPXv2VG5urlauXKmampoGx8nOzta9997rSWkA0KpZ/kH6qMSpA+1PkbommC7HawdKnPqoxCnLP+jojdFm+HydkUceeUS9e/dWXFycAgICNH36dKWlpcnPr+GhMzMzVV5e7tqKi4t9XSYAADDEoysjUVFRstvtKi0tddtfWlqqmJiYevt06tRJr776qg4ePKjvvvtOXbt21R133KGTTz65wXECAwMVGBjoSWlow6qqqhq8MtcQb+8aiIuLU0hIiKclAgCOwKMwEhAQoMTEROXm5mrs2LGSfp7Ampubq+nTpx+xb1BQkLp166affvpJr7zyiq644gqviwb+V2FhoRITE5tlrLy8PL5aHQCamMe39mZkZGjy5MkaOHCgBg0apJycHFVWViotLU2SlJqaqm7duik7O1uS9OGHH2rnzp1KSEjQzp07dc8998jpdOpPf/pT054J2qy4uDjl5eV51Kd2rQNP12yIa8ETBwHgeOVxGBk3bpz27t2rWbNmqaSkRAkJCVq7dq1rUuuOHTvc5oMcPHhQd999t7766iuFhYVp1KhReu6559S+ffsmOwm0Pr5e9tpbnnwcxJLXANA4Xq3AOn369AY/llm/fr3bz7///e/12WefeTMM2qjWtOw1S16jqVRVVUmS8vPzfTZGc63ACvwW302D405rWPaaJa/R1GqvyqWnpxuupGmEh4ebLgHHEcKIlzy9g+NY3vza6h0c8fHxPp0sOnToUJ8dG2hqtTcN+PL1wNu5VJ7iI0z8FmHES9zBAaA5RUVFaerUqc0ylq//EAB+izDiJU/v4DiWvzi4gwMA0JoRRrwUEhLi1V8O/MUBAIA7ny8HDwAAcCSEEQAAYBQf0wBoMnxPEABvEEYANBnuMgPgDcLI//DlEuS1qw76evXB1nD/vu3wQfWP8VPwvu3Srpb5SWLwvu3qH+Mn2+GDpktpVnxP0PHF0ytV3r5OcZUKx8pmWZZluoijqaioUGRkpMrLyxUREeGTMZpzCXJfa+lLkBe896Li/3Gd6TKaRMGwJxR/7pWmyziu5efnKzExkSsdPlD72Poazx0a0tj3b66M/MLXS5A313c+tIYlyA+GnaQBT/yo559/XvEt9K/fgsJCTZw4UUtGnWS6FLRhnl6pOpb5O8CxIIz8hi/XAWH58cax/IP0UYlTB9qfInVNMF2OVw6UOPVRiVOWf5DpUtCGebMeEq9TMKFlfiAPAABaDcIIAAAwijACAACMYs4IgCPy5S3vEre9AyCM4DhUVVUl6efbEn3F13c3+fqNtbk05y3vkyZN8vkYLf22d6C1IozguFO7SFN6errhSo5deHi46RKOia9veZe47R0AYQTHobFjx0pq/KqOtW9mnvj66681c+ZM3X///erRo0ej+3nyhtkaPhaoXQ13QBe74mN8NcUsVEN7nOajY/8seJ+9Ta6IC7QUhJFfsAT58SMqKkpTp05tdPv8/HyvL/HPnDnTo/ZtbaXJoB93KP+6MOkf10n/MF2N9+Il5V8XpoIfd0gaYrocAL9BGPlFa3jRbasvuN58HworTTZOa1gNV2JFXOB4Rxj5RWt40W2rL7jerDIpsdJkY7SG1XAlVsQFjneEkV+0hhddXnABAC0RYeQXvr6dtLnuGAAAoKUhjPyC20kBADCDMPILT28n9VTtOge+XK9Bah23kwIA2hbCyC88vZ3UW/Hx8W3q1lAAAI6GMAKgQa1haX6J+VTA8Y4wAqBBrWkulcR8KuB4RRjxUlVVleuFujGO5ZtJfTWPBTgaX8+lkphPBYAw4rXCwkIlJiZ63M+bZcvb2hLkOH4011wqiflUQFtGGPGSp0uQH8vn4m1tCXIAQNtCGPGSN0uQs/w4AAB1efX1tIsWLVJsbKyCgoKUlJSkzZs3H7F9Tk6OTj31VAUHB8vhcOiWW27RwYMt+5tlAQBA0/A4jKxYsUIZGRnKyspSfn6++vXrp5SUFO3Zs6fe9i+88ILuuOMOZWVlqaCgQEuWLNGKFSt05513HnPxAACg5fM4jMyfP1/p6elKS0tTnz59tHjxYoWEhGjp0qX1tt+4caOGDh2qCRMmKDY2Vueff77Gjx9/1KspAACgbfAojBw6dEh5eXlKTk7+9QB+fkpOTtamTZvq7TNkyBDl5eW5wsdXX32l1atXa9SoUcdQNgAAaC08msBaVlammpoaRUdHu+2Pjo5ucM2NCRMmqKysTGeddZYsy9Lhw4f1//7f/zvixzTV1dWqrq52/VxRUeFJmQAAoAXxagKrJ9avX6/Zs2frL3/5i/Lz87Vy5Uq9+eabuv/++xvsk52drcjISNfmcDh8XSYAADDEoysjUVFRstvtKi0tddtfWlqqmJiYevvMnDlTV111lWvhpL59+6qyslLXXnut7rrrLvn51c1DmZmZysjIcP1cUVFBIAEAoJXyKIwEBAQoMTFRubm5rmWinU6ncnNzNX369Hr7VFVV1QkcdrtdkmRZVr19AgMDFRgY6ElpAI4Dnn5NguT9VyXwNQlA6+HxomcZGRmaPHmyBg4cqEGDBiknJ0eVlZVKS0uTJKWmpqpbt27Kzs6WJI0ZM0bz589X//79lZSUpC+++EIzZ87UmDFjXKEEQOvg7dckSJ5/VQJfkwC0Hh6HkXHjxmnv3r2aNWuWSkpKlJCQoLVr17omte7YscPtSsjdd98tm82mu+++Wzt37lSnTp00ZswYPfjgg013FgCOC55+TYLk/Vcl8DUJQOthsxr6rOQ4UlFRocjISJWXlysiIsJ0OQAAoBEa+/7t87tpAAAAjoQwAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKO8CiOLFi1SbGysgoKClJSUpM2bNzfY9pxzzpHNZquzjR492uuiAQBA6+FxGFmxYoUyMjKUlZWl/Px89evXTykpKdqzZ0+97VeuXKndu3e7tq1bt8put+vyyy8/5uIBAEDL53EYmT9/vtLT05WWlqY+ffpo8eLFCgkJ0dKlS+tt37FjR8XExLi2d955RyEhIYQRAAAgycMwcujQIeXl5Sk5OfnXA/j5KTk5WZs2bWrUMZYsWaIrr7xSoaGhDbaprq5WRUWF2wYAAFonj8JIWVmZampqFB0d7bY/OjpaJSUlR+2/efNmbd26VVOnTj1iu+zsbEVGRro2h8PhSZkAAKAFada7aZYsWaK+fftq0KBBR2yXmZmp8vJy11ZcXNxMFQIAgObm70njqKgo2e12lZaWuu0vLS1VTEzMEftWVlbqxRdf1H333XfUcQIDAxUYGOhJaQAAoIXy6MpIQECAEhMTlZub69rndDqVm5urwYMHH7HvSy+9pOrqak2aNMm7SgEAQKvk0ZURScrIyNDkyZM1cOBADRo0SDk5OaqsrFRaWpokKTU1Vd26dVN2drZbvyVLlmjs2LE64YQTmqZyAADQKngcRsaNG6e9e/dq1qxZKikpUUJCgtauXeua1Lpjxw75+blfcNm2bZs2bNigt99+u2mqBgAArYbNsizLdBFHU1FRocjISJWXlysiIsJ0OQAAoBEa+/7Nd9MAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKK/CyKJFixQbG6ugoCAlJSVp8+bNR2y/b98+TZs2TV26dFFgYKBOOeUUrV692quCAQBA6+LvaYcVK1YoIyNDixcvVlJSknJycpSSkqJt27apc+fOddofOnRII0aMUOfOnfXyyy+rW7du+uabb9S+ffumqB8AALRwNsuyLE86JCUl6cwzz9TChQslSU6nUw6HQzNmzNAdd9xRp/3ixYv10EMPqbCwUO3atfOqyIqKCkVGRqq8vFwRERFeHQMAADSvxr5/e/QxzaFDh5SXl6fk5ORfD+Dnp+TkZG3atKnePq+//roGDx6sadOmKTo6Wqeffrpmz56tmpqaBseprq5WRUWF2wYAAFonj8JIWVmZampqFB0d7bY/OjpaJSUl9fb56quv9PLLL6umpkarV6/WzJkz9fDDD+uBBx5ocJzs7GxFRka6NofD4UmZAACgBfH53TROp1OdO3fWk08+qcTERI0bN0533XWXFi9e3GCfzMxMlZeXu7bi4mJflwkAAAzxaAJrVFSU7Ha7SktL3faXlpYqJiam3j5dunRRu3btZLfbXfvi4+NVUlKiQ4cOKSAgoE6fwMBABQYGelIaAABooTy6MhIQEKDExETl5ua69jmdTuXm5mrw4MH19hk6dKi++OILOZ1O177t27erS5cu9QYRAADQtnj8MU1GRoaeeuopPfPMMyooKND111+vyspKpaWlSZJSU1OVmZnpan/99dfr+++/10033aTt27frzTff1OzZszVt2rSmOwsAANBiebzOyLhx47R3717NmjVLJSUlSkhI0Nq1a12TWnfs2CE/v18zjsPh0FtvvaVbbrlFZ5xxhrp166abbrpJt99+e9OdBQAAaLE8XmfEBNYZAQCg5fHJOiMAAABNjTACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjPIqjCxatEixsbEKCgpSUlKSNm/e3GDbZcuWyWazuW1BQUFeFwwAAFoXj8PIihUrlJGRoaysLOXn56tfv35KSUnRnj17GuwTERGh3bt3u7ZvvvnmmIoGAACth8dhZP78+UpPT1daWpr69OmjxYsXKyQkREuXLm2wj81mU0xMjGuLjo4+pqIBAEDr4VEYOXTokPLy8pScnPzrAfz8lJycrE2bNjXY78cff1T37t3lcDh08cUX69NPP/W+YgAA0Kp4FEbKyspUU1NT58pGdHS0SkpK6u1z6qmnaunSpXrttde0fPlyOZ1ODRkyRN9++22D41RXV6uiosJtAwAArZPP76YZPHiwUlNTlZCQoN///vdauXKlOnXqpCeeeKLBPtnZ2YqMjHRtDofD12UCAABDPAojUVFRstvtKi0tddtfWlqqmJiYRh2jXbt26t+/v7744osG22RmZqq8vNy1FRcXe1ImAABoQTwKIwEBAUpMTFRubq5rn9PpVG5urgYPHtyoY9TU1OiTTz5Rly5dGmwTGBioiIgItw0AALRO/p52yMjI0OTJkzVw4EANGjRIOTk5qqysVFpamiQpNTVV3bp1U3Z2tiTpvvvu0+9+9zv16tVL+/bt00MPPaRvvvlGU6dObdozAQAALZLHYWTcuHHau3evZs2apZKSEiUkJGjt2rWuSa07duyQn9+vF1x++OEHpaenq6SkRB06dFBiYqI2btyoPn36NN1ZAACAFstmWZZluoijqaioUGRkpMrLy/nIBgCAFqKx7998Nw0AADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjvAojixYtUmxsrIKCgpSUlKTNmzc3qt+LL74om82msWPHejMsAABohTwOIytWrFBGRoaysrKUn5+vfv36KSUlRXv27Dliv6KiIv3xj3/U2Wef7XWxAACg9fE4jMyfP1/p6elKS0tTnz59tHjxYoWEhGjp0qUN9qmpqdHEiRN177336uSTTz6mggEAQOviURg5dOiQ8vLylJyc/OsB/PyUnJysTZs2NdjvvvvuU+fOnTVlypRGjVNdXa2Kigq3DQAAtE4ehZGysjLV1NQoOjrabX90dLRKSkrq7bNhwwYtWbJETz31VKPHyc7OVmRkpGtzOByelAkAAFoQn95Ns3//fl111VV66qmnFBUV1eh+mZmZKi8vd23FxcU+rBIAAJjk70njqKgo2e12lZaWuu0vLS1VTExMnfZffvmlioqKNGbMGNc+p9P588D+/tq2bZt69uxZp19gYKACAwM9KQ0AALRQHl0ZCQgIUGJionJzc137nE6ncnNzNXjw4Drt4+Li9Mknn2jLli2u7aKLLtLw4cO1ZcsWPn4BAACeXRmRpIyMDE2ePFkDBw7UoEGDlJOTo8rKSqWlpUmSUlNT1a1bN2VnZysoKEinn366W//27dtLUp39AACgbfI4jIwbN0579+7VrFmzVFJSooSEBK1du9Y1qXXHjh3y82NhVwAA0Dg2y7Is00UcTUVFhSIjI1VeXq6IiAjT5QAAgEZo7Ps3lzAAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABglFdhZNGiRYqNjVVQUJCSkpK0efPmBtuuXLlSAwcOVPv27RUaGqqEhAQ999xzXhcMAABaF4/DyIoVK5SRkaGsrCzl5+erX79+SklJ0Z49e+pt37FjR911113atGmTPv74Y6WlpSktLU1vvfXWMRcPAABaPptlWZYnHZKSknTmmWdq4cKFkiSn0ymHw6EZM2bojjvuaNQxBgwYoNGjR+v+++9vVPuKigpFRkaqvLxcERERnpQLAAAMaez7t0dXRg4dOqS8vDwlJyf/egA/PyUnJ2vTpk1H7W9ZlnJzc7Vt2zYNGzaswXbV1dWqqKhw2wAAQOvkURgpKytTTU2NoqOj3fZHR0erpKSkwX7l5eUKCwtTQECARo8erccee0wjRoxosH12drYiIyNdm8Ph8KRMAADQgjTL3TTh4eHasmWL/v3vf+vBBx9URkaG1q9f32D7zMxMlZeXu7bi4uLmKBMAABjg70njqKgo2e12lZaWuu0vLS1VTExMg/38/PzUq1cvSVJCQoIKCgqUnZ2tc845p972gYGBCgwM9KQ0AADQQnl0ZSQgIECJiYnKzc117XM6ncrNzdXgwYMbfRyn06nq6mpPhgYAAK2UR1dGJCkjI0OTJ0/WwIEDNWjQIOXk5KiyslJpaWmSpNTUVHXr1k3Z2dmSfp7/MXDgQPXs2VPV1dVavXq1nnvuOT3++ONNeyYAAKBF8jiMjBs3Tnv37tWsWbNUUlKihIQErV271jWpdceOHfLz+/WCS2VlpW644QZ9++23Cg4OVlxcnJYvX65x48Y13VkAAIAWy+N1RkxgnREAAFoen6wzAgAA0NQIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKI/XGQEAAJ6pqqpSYWFho9sfOHBARUVFio2NVXBwsEdjxcXFKSQkxNMSjSKMAADgY4WFhUpMTGyWsfLy8jRgwIBmGaupEEYAAPCxuLg45eXlNbp9QUGBJk2apOXLlys+Pt7jsVoawggAAD4WEhLi1dWK+Pj4FneVwxtMYAUAAEYRRgAAgFGEEQAAYBRhBAAAGMUEVgAAPPT5559r//79Pjt+QUGB27++Eh4ert69e/t0jMYgjAAA4IHPP/9cp5xySrOMNWnSJJ+PsX37duOBhDACAIAHaq+IeLMGSGMdywqsjVW7lokvr/A0FmEEAAAv+HoNkKFDh/rs2McbJrACAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwChu7QUAwAO2wwfVP8ZPwfu2S7ta7t/0wfu2q3+Mn2yHD5ouhTACAIAngn7cofzrwqR/XCf9w3Q13ouXlH9dmAp+3CFpiNFaCCMAAHjgYNhJGvDEj3r++ecVHxdnuhyvFRQWauLEiVoy6iTTpRBGAADwhOUfpI9KnDrQ/hSpa4Lpcrx2oMSpj0qcsvyDTJfCBFYAAGAWV0YAAPBAVVWVJCk/P99nYzTXF+UdLwgjAAB4oLCwUJKUnp5uuJKmER4ebroEwggAAJ4YO3asJCkuLk4hISE+GaOgoECTJk3S8uXLFR8f75MxpJ+DSO/evX12/MYijAAA4IGoqChNnTq1WcaKj4/XgAEDmmUsk5jACgAAjPIqjCxatEixsbEKCgpSUlKSNm/e3GDbp556SmeffbY6dOigDh06KDk5+YjtAQBA2+JxGFmxYoUyMjKUlZWl/Px89evXTykpKdqzZ0+97devX6/x48dr3bp12rRpkxwOh84//3zt3LnzmIsHAAAtn82yLMuTDklJSTrzzDO1cOFCSZLT6ZTD4dCMGTN0xx13HLV/TU2NOnTooIULFyo1NbVRY1ZUVCgyMlLl5eWKiIjwpFwAAFqc/Px8JSYmKi8vr0XPGWns+7dHV0YOHTqkvLw8JScn/3oAPz8lJydr06ZNjTpGVVWVfvrpJ3Xs2LHBNtXV1aqoqHDbAABA6+RRGCkrK1NNTY2io6Pd9kdHR6ukpKRRx7j99tvVtWtXt0DzW9nZ2YqMjHRtDofDkzIBAEAL0qx308yZM0cvvvii/v73vysoqOG18DMzM1VeXu7aiouLm7FKAADQnDxaZyQqKkp2u12lpaVu+0tLSxUTE3PEvn/+8581Z84cvfvuuzrjjDOO2DYwMFCBgYGelAYAAFooj66MBAQEKDExUbm5ua59TqdTubm5Gjx4cIP95s2bp/vvv19r167VwIEDva8WAAC0Oh6vwJqRkaHJkydr4MCBGjRokHJyclRZWam0tDRJUmpqqrp166bs7GxJ0ty5czVr1iy98MILio2Ndc0tCQsLU1hYWBOeCgAAx6eqqirXd9o0Ru2X2HnzZXa+XKbeVzwOI+PGjdPevXs1a9YslZSUKCEhQWvXrnVNat2xY4f8/H694PL444/r0KFDuuyyy9yOk5WVpXvuuefYqgcAoAUoLCxUYmKix/0mTZrkcZ+WeDuwx+uMmMA6IwCAlszTKyMHDhxQUVGRYmNjFRwc7NFYx9OVkca+fxNGAACAT/hk0TMAAICmRhgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAY5W+6gMao/WLhiooKw5UAAIDGqn3frn0fb0iLCCP79++XJDkcDsOVAAAAT+3fv1+RkZEN/t5mHS2uHAecTqd27dql8PBw2Ww20+V4paKiQg6HQ8XFxYqIiDBdTpvH83H84Lk4fvBcHD9ay3NhWZb279+vrl27ys+v4ZkhLeLKiJ+fn0488UTTZTSJiIiIFv1/rNaG5+P4wXNx/OC5OH60hufiSFdEajGBFQAAGEUYAQAARhFGmklgYKCysrIUGBhouhSI5+N4wnNx/OC5OH60teeiRUxgBQAArRdXRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGmtjVV1+tsWPH1vu72NhY2Ww22Ww2hYSEqG/fvvrrX//avAW2QvU95i+//LKCgoL08MMP6+qrr5bNZtOcOXPc2rz66qtuK/quX79eNptNp512mmpqatzatm/fXsuWLfPVKbRqtY+/zWZTu3btFB0drREjRmjp0qVyOp2ux/1I2/r1602fRqvx2+ejR48e+tOf/qSDBw+62tT3HJx11lkGq2759u7dq+uvv14nnXSSAgMDFRMTo5SUFL3//vuKioqq8/pU6/7771d0dLR++uknLVu2TDabTfHx8XXavfTSS7LZbIqNjfXxmfgGYaSZ3Xfffdq9e7e2bt2qSZMmKT09XWvWrDFdVqvy17/+VRMnTtTjjz+uW2+9VZIUFBSkuXPn6ocffjhq/6+++krPPvusr8tsU0aOHKndu3erqKhIa9as0fDhw3XTTTfpwgsv1JAhQ7R7927XdsUVV7ja125DhgwxfQqtSu3j+9VXX2nBggV64oknlJWV5dbm6aefdnsOXn/9dUPVtg6XXnqpPvroIz3zzDPavn27Xn/9dZ1zzjkqLy/XpEmT9PTTT9fpY1mWli1bptTUVLVr106SFBoaqj179mjTpk1ubZcsWaKTTjqpWc7FFwgjzSw8PFwxMTE6+eSTdfvtt6tjx4565513TJfVasybN08zZszQiy++qLS0NNf+5ORkxcTEKDs7+6jHmDFjhrKyslRdXe3LUtuU2r8Eu3XrpgEDBujOO+/Ua6+9pjVr1ujZZ59VTEyMawsODna1r90CAgJMn0KrUvv4OhwOjR07VsnJyXVeh9q3b+/2HHTs2NFQtS3fvn379M9//lNz587V8OHD1b17dw0aNEiZmZm66KKLNGXKFG3fvl0bNmxw6/f+++/rq6++0pQpU1z7/P39NWHCBC1dutS179tvv9X69es1YcKEZjunpkYYMcTpdOqVV17RDz/8wAttE7n99tt1//33a9WqVbrkkkvcfme32zV79mw99thj+vbbb494nJtvvlmHDx/WY4895sty27xzzz1X/fr108qVK02X0qZt3bpVGzdu5HXIh8LCwhQWFqZXX3213j9y+vbtqzPPPNMtYEg/X50aMmSI4uLi3PZfc801+tvf/qaqqipJ0rJlyzRy5EhFR0f77iR8jDDSzG6//XaFhYUpMDBQl112mTp06KCpU6eaLqvFW7NmjebNm6fXXntN5513Xr1tLrnkEiUkJNS5HP1bISEhysrKUnZ2tsrLy31RLn4RFxenoqIi02W0OatWrVJYWJiCgoLUt29f7dmzR7fddptbm/Hjx7veRGvfSOEdf39/LVu2TM8884zat2+voUOH6s4779THH3/sajNlyhS99NJL+vHHHyVJ+/fv18svv6xrrrmmzvH69++vk08+WS+//LLro5z62rUkhJFmdtttt2nLli167733lJSUpAULFqhXr16my2rxzjjjDMXGxiorK8v1H3N95s6dq2eeeUYFBQVHPN6UKVN0wgknaO7cuU1dKv6HZVluk4jRPIYPH64tW7boww8/1OTJk5WWlqZLL73Urc2CBQu0ZcsW1zZixAhD1bYOl156qXbt2qXXX39dI0eO1Pr16zVgwADXxPjx48erpqZGf/vb3yRJK1askJ+fn8aNG1fv8a655ho9/fTTev/991VZWalRo0Y116n4BGGkmUVFRalXr146++yz9dJLL+nGG2/UZ599ZrqsFq9bt25av369du7cqZEjR2r//v31ths2bJhSUlKUmZl5xOP5+/vrwQcf1COPPKJdu3b5omRIKigoUI8ePUyX0eaEhoaqV69e6tevn5YuXaoPP/xQS5YscWsTExOjXr16ubbQ0FBD1bYeQUFBGjFihGbOnKmNGzfq6quvdl2pjYiI0GWXXeaayPr000/riiuuUFhYWL3Hmjhxoj744APdc889uuqqq+Tv799s5+ELhBGDHA6Hxo0bd9Q3RjRO9+7d9f7776ukpOSIgWTOnDl644036sxG/63LL79cp512mu69915flNvmvffee/rkk0/q/EWO5uXn56c777xTd999tw4cOGC6nDalT58+qqysdP08ZcoUbdiwQatWrdLGjRvdJq7+VseOHXXRRRfp/fffb/Ef0UiEEZ8oLy93u7y5ZcsWFRcX19v2pptu0htvvKH//Oc/zVxl6+RwOLR+/Xrt2bNHKSkpqqioqNOmb9++mjhxoh599NGjHm/OnDlaunSp2wsGPFddXa2SkhLt3LlT+fn5mj17ti6++GJdeOGFSk1NNV1em3f55ZfLbrdr0aJFpktplb777jude+65Wr58uT7++GN9/fXXeumllzRv3jxdfPHFrnbDhg1Tr169lJqaqri4uKPe0r5s2TKVlZXVmeDaEhFGfGD9+vXq37+/29bQX9d9+vTR+eefr1mzZjVzla3XiSeeqPXr16usrKzBQHLffffJ6XQe9Vjnnnuuzj33XB0+fNgXpbYZa9euVZcuXRQbG6uRI0dq3bp1evTRR/Xaa6/JbrebLq/N8/f31/Tp0zVv3jyCtw+EhYW55ggOGzZMp59+umbOnKn09HQtXLjQ1c5ms+maa67RDz/80KirHcHBwTrhhBN8WXqzsVmWZZkuAgAAtF1cGQEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABj1/wG6XsInL9d3HgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = []\n",
    "models.append(('LR', random_search_lr.best_estimator_))\n",
    "models.append(('KNN', random_search_knn.best_estimator_))\n",
    "models.append(('DT', random_search_dt.best_estimator_))\n",
    "models.append(('RF', random_search_rf.best_estimator_))\n",
    "models.append(('SVM', random_search_svc.best_estimator_))\n",
    "\n",
    "# Model Selection by Accuracy\n",
    "seed = 7\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "    cv_results = model_selection.cross_val_score(model, data_X[list(sfs1.k_feature_names_)], data_y, cv=kfold, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%4s: %8f (%8f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\n",
    "    print(msg)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Model Selection')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n",
      "{'bootstrap': False,\n",
      " 'max_depth': 21,\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 2,\n",
      " 'n_estimators': 1600}\n",
      "0.8980991670595632\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=1234)\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=10)]\n",
    "max_depth.append(None)\n",
    "\n",
    "grid_list = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_leaf': [int(x) for x in np.linspace(1, 10, num=1)],\n",
    "    'min_samples_split': [int(x) for x in np.linspace(2, 20, num=1)],\n",
    "    'n_estimators': [int(x) for x in np.linspace(start=200, stop=2000, num=20)]\n",
    "}\n",
    "\n",
    "random_search_rf = GridSearchCV(estimator=rf, param_grid=rand_list, cv=5, n_jobs=-1, verbose=2, scoring=\"accuracy\")\n",
    "random_search_rf.fit(train_X[list(sfs1.k_feature_names_)], train_y)\n",
    "pp.pprint(random_search_rf.best_params_)\n",
    "pp.pprint(random_search_rf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             1   2    3    4    5    6   7    8    9   10  ...   22   23  24  \\\n",
      "0     0.376623  68  111   84   80   75  74   87   75   86  ...   75   67  67   \n",
      "1     0.525974  89  134  104  109  112  67   95  120  112  ...  112  109  63   \n",
      "2     0.344156  76  171   74   74   88  50   46   86   78  ...   82   66  53   \n",
      "3     0.376623  45   95   66   73   57  56   53   77   65  ...   62   68  59   \n",
      "4     0.512987  76  151   89   93   49  53   71   82   90  ...   90   92  53   \n",
      "...        ...  ..  ...  ...  ...  ...  ..  ...  ...  ...  ...  ...  ...  ..   \n",
      "1539  0.415584  65  144   82   82  103  67   75  114   86  ...   82   94  72   \n",
      "1540  0.428571  80  144   93   90   77  75   88   76   97  ...   97   96  78   \n",
      "1541  0.551948  85  129  113  113  113  93  107   91  108  ...  108   74  90   \n",
      "1542  0.402597  59  140   74   78  107  64   77  114   83  ...   79   55  64   \n",
      "1543  0.448052  74  118   94   94  109  80   94   77   96  ...   91   54  76   \n",
      "\n",
      "      25   26  27        28  29   30        31  \n",
      "0     84   74  67  0.528662  64  133  0.800000  \n",
      "1     63   96  91  0.503185  92  109  0.676923  \n",
      "2     84   72  86  0.394904  65  142  0.507692  \n",
      "3     59   74  81  0.439490  45  119  0.769231  \n",
      "4     83   97  57  0.560510  79  121  0.753846  \n",
      "...   ..  ...  ..       ...  ..  ...       ...  \n",
      "1539  63   82  89  0.554140  61  103  0.284615  \n",
      "1540  64   84  99  0.528662  80  105  0.592308  \n",
      "1541  85  113  90  0.598726  89  146  0.238462  \n",
      "1542  63   78  63  0.554140  59  119  0.869231  \n",
      "1543  75   97  80  0.471338  74   59  0.669231  \n",
      "\n",
      "[1544 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('dataset/test_open.csv')\n",
    "\n",
    "print(test)\n",
    "\n",
    "# best model\n",
    "best_random_model = random_search_rf.best_estimator_\n",
    "best_random_predict = best_random_model.predict(test[list(sfs1.k_feature_names_)])\n",
    "\n",
    "# predict_str = []\n",
    "\n",
    "pd.DataFrame(encoder.inverse_transform(best_random_predict)).to_csv('predict.csv')    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11705b00557649c2ab2263af14686c27a24b2cec0cd0adde932d16ea4aa3435f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
